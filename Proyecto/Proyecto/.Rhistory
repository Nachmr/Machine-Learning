#Ejercicio 2
library(ISLR)
library(MASS)
fix(Boston)
attach(Boston)
lm.fit = lm(crim~., data=Boston)
plot(lm.fit)
View(Boston)
[[2]]
plot(lm(crim~Boston[2]))
lm(crim~Boston[[2]])
lm.fit = lm(crim~Boston[[x]])
lm.fit = lm(crim~Boston[[seq(along=x)]])
x <- 2:12
lm.fit = lm(crim~Boston[[seq(along=x)]])
lm.fit = lm(crim~Boston[[seq(x)]])
lm(crim~Boston[[1]])
lm(crim~Boston[[2]])
lm(crim~Boston[[3]])
lm(crim~Boston[[4]])
lm(crim~Boston[[5]])
View(Boston)
View(Boston)
cor(Boston)
cor(Boston)
max(cor(Boston))
source('~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P1/scriptP1.R')
reg[1] <- lm(crim~Boston[[2]]) #crim vs zn
reg[2] <- lm(crim~Boston[[3]]) #crim vs indus
reg[3] <- lm(crim~Boston[[4]]) #crim vs chas
reg[4] <- lm(crim~Boston[[5]]) #crim vs nos
reg[5] <- lm(crim~Boston[[6]]) #crim vs rm
reg[6] <- lm(crim~Boston[[7]]) #crim vs age
reg[7] <- lm(crim~Boston[[8]]) #crim vs dis
reg[8] <- lm(crim~Boston[[9]]) #crim vs rad
reg[9] <- lm(crim~Boston[[10]]) #crim vs tax
reg[10] <- lm(crim~Boston[[11]]) #crim vs pratio
reg[11] <- lm(crim~Boston[[12]]) #crim vs black
source('~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P1/scriptP1.R')
#guardo los valores de las rectas de regresion en el vector reg:
reg <- 1
reg[1] <- lm(crim~Boston[[2]]) #crim vs zn
reg[2] <- lm(crim~Boston[[3]]) #crim vs indus
reg[3] <- lm(crim~Boston[[4]]) #crim vs chas
reg[4] <- lm(crim~Boston[[5]]) #crim vs nos
reg[5] <- lm(crim~Boston[[6]]) #crim vs rm
reg[6] <- lm(crim~Boston[[7]]) #crim vs age
reg[7] <- lm(crim~Boston[[8]]) #crim vs dis
reg[8] <- lm(crim~Boston[[9]]) #crim vs rad
reg[9] <- lm(crim~Boston[[10]]) #crim vs tax
reg[10] <- lm(crim~Boston[[11]]) #crim vs pratio
reg[11] <- lm(crim~Boston[[12]]) #crim vs black
reg[2]
cofint(lm(crim~Boston[[3]]))
confit(lm(crim~Boston[[3]]))
confint(lm(crim~Boston[[3]]))
confint(reg[2])
summary(lm(crim~Boston[[2]]))
summary(lm(crim~Boston[[3]]))
summary(lm(crim~Boston[[4]]))
summary(lm(crim~Boston[[5]]))
summary(lm(crim~Boston[[6]]))
summary(lm(crim~Boston[[7]]))
summary(lm(crim~Boston[[8]]))
summary(lm(crim~Boston[[9]]))
summary(lm(crim~Boston[[10]]))
summary(lm(crim~Boston[[11]]))
summary(lm(crim~Boston[[12]]))
help(boston)
help(Boston)
sd(lm(crim~Boston[[12]]))
sd(Boston[[12]])
source('~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P1/scriptP1.R')
sd(Boston[[4]])
reg[12] <- lm(crim~Boston[[13]]) #crim vs lstat
reg[13] <- lm(crim~Boston[[14]]) #crim vs medv
sd(Boston[[14]])
sd(Boston[[zn]])
sd(Boston[[2]])
plot(lm(crim~Boston[[4]]))
plot(lm(crim~Boston[[4]]))
plot(lm(crim~Boston[[4]]))
plot(lm(crim~Boston[[4]]))
lm(crim~.)
lm.fit = lm(crim~.)
lm.fit = lm ( medv∼. , data = Boston )
lm.fit = lm ( medv~. , data = Boston )
lm.fit = lm ( crim~. , data = Boston )
summary(lm.fit)
plot(lm.fit)
source('~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P1/scriptP1.R')
reg[2] <- lm(crim~Boston[[3]]) #crim vs indus
reg[3] <- lm(crim~Boston[[4]]) #crim vs chas
#######################################
#Ejercicio 2
#######################################
library(ISLR)
library(MASS)
fix(Boston)
attach(Boston)
#apartado a)
# i)
#guardo los valores de las rectas de regresion en el vector reg:
reg <- 1
reg[1] <- lm(crim~Boston[[2]]) #crim vs zn
reg[2] <- lm(crim~Boston[[3]]) #crim vs indus
reg[3] <- lm(crim~Boston[[4]]) #crim vs chas
reg[4] <- lm(crim~Boston[[5]]) #crim vs nos
reg[5] <- lm(crim~Boston[[6]]) #crim vs rm
reg[6] <- lm(crim~Boston[[7]]) #crim vs age
reg[7] <- lm(crim~Boston[[8]]) #crim vs dis
reg[8] <- lm(crim~Boston[[9]]) #crim vs rad
reg[9] <- lm(crim~Boston[[10]]) #crim vs tax
reg[10] <- lm(crim~Boston[[11]]) #crim vs pratio
reg[11] <- lm(crim~Boston[[12]]) #crim vs black
reg[12] <- lm(crim~Boston[[13]]) #crim vs lstat
reg[13] <- lm(crim~Boston[[14]]) #crim vs medv
#ii)
summary(lm(crim~Boston[[4]])) #mal
sd(Boston[[4]]) #mal
#buscar las variables que tengan MENOR p-valor
#iii)
plot(lm(crim~Boston[[4]]))
lm.fit = lm(crim~. , data = Boston)
#par(mfrow=c(2,2), oma=c(0,0,4,0))
#plot(cri)
library(ISLR)
library(MASS)
fix(OJ)
attach(OJ)
1200/1500
?cv.lm
??cv.lm
52
-4+5
+
2+
2
library(MASS)
library(ISLR)
library(e1071)
library(MASS)
library(car)
## a simple example
data(cats, package = "MASS")
m <- svm(Sex~., data = cats)
plot(m, cats)
data(cats, package = "MASS")
m <- svm(Sex~., data = cats)
plot(m, cats)
library(ISLR)
library(e1071)
library(MASS)
library(car)
library(leaps)
library(DAAG)
library(boot)
#Analisis de la base de datos
data(cats, package = "MASS")
m <- svm(Sex~., data = cats)
plot(m, cats)
path = "~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Proyecto/Proyecto"
setwd(path)
#Lectura de dataset
Airfoil=read.table("datos/airfoil_self_noise.txt",header=T, na.strings="?")
Airfoil=na.omit(Airfoil) #Elimina las muestras que tienen algún dato perdido
attach(Airfoil)
#Librerias utilizadas
library(ISLR)
library(e1071)
library(MASS)
library(car)
library(leaps)
library(DAAG)
library(boot)
#Analisis de la base de datos
summary(Airfoil) #Muestra información básica sobre la base de datos
cor(Airfoil) #Muestra la matriz de correlación entre las variables de la BD
pairs(Airfoil) #Muestra todas las gráficas de todas las variables frente a todas las variables de la base de datos
set.seed(1)
#Regresión generalizada múltiple
glmFit = glm(modelo, data = train)
pred = predict.glm(glmFit, test, type = "response", se.fit = TRUE)
names(pred)
#SVM
set.seed (1)
#Buscamos el valor çoptimo para cost y gamma
tune.out = tune(svm, modelo, data = train , kernel = "radial", ranges = list(cost = c(0.1, 1, 10), gamma = c(0.5, 1, 2)))
svm.fit = svm(modelo, data = train, kernel = "radial")
pred= predict(svm.fit, test)
plot(svm.fit, data=test)
set.seed(1)
indices = sample (dim(Airfoil)[1], 1200, replace=FALSE)
train = Airfoil[indices, ]
test = Airfoil[-indices, ]
SSPL.train = train[, "SSPL"]
SSPL.test = test[, "SSPL"]
regfit.full = regsubsets(SSPL~Frequency*AOA*CL*FSV*SSDT, data = train, nvmax = 31, method = "exhaustive")
reg.summary = summary(regfit.full)
reg.summary
plot(reg.summary$rsq, xlab = " Número de variables ", ylab = "RSQ", type ="l", main = "Selección de variables")
reg.summary = summary(regfit.full)
regfit.full = regsubsets(SSPL~Frequency*AOA*CL*FSV*SSDT, data = train, nvmax = 31, method = "exhaustive")
set.seed(1)
#Regresión generalizada múltiple
glmFit = glm(modelo, data = train)
modelo = SSPL ~ Frequency + AOA + FSV + Frequency:AOA + Frequency:CL + AOA:CL + Frequency:FSV + AOA:FSV + CL:FSV + Frequency:SSDT + CL:SSDT + FSV:SSDT + Frequency:AOA:CL + Frequency:CL:FSV + Frequency:AOA:SSDT + Frequency:CL:SSDT + AOA:FSV:SSDT + Frequency:AOA:CL:FSV + Frequency:AOA:CL:SSDT + Frequency:CL:FSV:SSDT
#Ajuste de modelos
set.seed(1)
#Regresión generalizada múltiple
glmFit = glm(modelo, data = train)
pred = predict.glm(glmFit, test, type = "response", se.fit = TRUE)
names(pred)
#SVM
set.seed (1)
#Buscamos el valor çoptimo para cost y gamma
tune.out = tune(svm, modelo, data = train , kernel = "radial", ranges = list(cost = c(0.1, 1, 10), gamma = c(0.5, 1, 2)))
svm.fit = svm(modelo, data = train, kernel = "radial")
pred= predict(svm.fit, test)
plot(svm.fit, data=test)
# PASO 1:   Carga Package, Set de datos y fija numeros aleatorios
library(C50); library(rpart); data(churn); set.seed(1)
install.packages("C50")
library(C50); library(rpart); data(churn); set.seed(1)
library(C50); library(rpart); data(churn); set.seed(1)
install.packages("C50")
Variables  <-c(4,7,16,19,17,20) # Vector con No. de variables a usar
datos      <-churnTrain[,Variables]  # Agrega set Entrenamiento a tabla datos
datos      <-rbind(datos,churnTest [,Variables]) # Agrega set de Test a tabla datos
Variables  <-c(4,7,16,19,17,20) # Vector con No. de variables a usar
datos      <-train[,Variables]  # Agrega set Entrenamiento a tabla datos
datos      <-train[,Variables]  # Agrega set Entrenamiento a tabla datos
datos      <-train  # Agrega set Entrenamiento a tabla datos
datos      <-rbind(datos,churnTest [,Variables]) # Agrega set de Test a tabla datos
datos      <-rbind(datos,train) # Agrega set de Test a tabla datos
Etiquetas  <-c("Plan_Internacional", "Min_En_Dia",
"Min_Internacionales","Reclamos",
"Llamadas_Internacionales","Desafiliado") # nombres de columnas
colnames(datos) <-Etiquetas;      # Asigna nombre a columnas
# -------------------------------------------------------------------------------
# PASO 2: Asginar los k-fold al set de datos
Folds         <-10
datos$kfold   <-sample(1:Folds,nrow(datos),replace=T)
# --------------------------------------------------------------------------------
# PASO 3: Crear tabla Iteraciones, y ejecutar 10 modelos con k-fold diferente
Iteraciones   <-data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:Folds)
{
Test          <-subset(datos,kfold==i)    # Crea set TEST para i iteracion
Entrenamiento <-subset(datos,!kfold==i)   # Crea set Entren. para i iteracion
ModeloArbol   <-rpart(Desafiliado ~ .,data=Entrenamiento) # Crea Modelo
Prediccion    <- predict(ModeloArbol, Test,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
Aciertos      <-MC[1,1]/(MC[1,1]+MC[2,1])
Iteraciones   <-rbind(Iteraciones,
data.frame(iteracion=i,
acierto=Aciertos))  # resultado en cada iteracion
}
library(C50); library(rpart); data(churn); set.seed(1)
library(rpart); data(churn); set.seed(1)
library(rpart);  set.seed(1)
datos      <-train  # Agrega set Entrenamiento a tabla datos
datos      <-rbind(datos,train) # Agrega set de Test a tabla datos
Etiquetas  <-c("Plan_Internacional", "Min_En_Dia",
"Min_Internacionales","Reclamos",
"Llamadas_Internacionales","Desafiliado") # nombres de columnas
colnames(datos) <-Etiquetas;      # Asigna nombre a columnas
# -------------------------------------------------------------------------------
# PASO 2: Asginar los k-fold al set de datos
Folds         <-10
datos$kfold   <-sample(1:Folds,nrow(datos),replace=T)
# --------------------------------------------------------------------------------
# PASO 3: Crear tabla Iteraciones, y ejecutar 10 modelos con k-fold diferente
Iteraciones   <-data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:Folds)
{
Test          <-subset(datos,kfold==i)    # Crea set TEST para i iteracion
Entrenamiento <-subset(datos,!kfold==i)   # Crea set Entren. para i iteracion
ModeloArbol   <-rpart(Desafiliado ~ .,data=Entrenamiento) # Crea Modelo
Prediccion    <- predict(ModeloArbol, Test,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
Aciertos      <-MC[1,1]/(MC[1,1]+MC[2,1])
Iteraciones   <-rbind(Iteraciones,
data.frame(iteracion=i,
acierto=Aciertos))  # resultado en cada iteracion
}
# --------------------------------------------------------------------------------
ModeloArbol   <-rpart(Desafiliado ~ .,data=Entrenamiento) # Crea Modelo
Prediccion    <- predict(ModeloArbol, Test,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
for (i in 1:Folds)
{
Test          <-subset(datos,kfold==i)    # Crea set TEST para i iteracion
Entrenamiento <-subset(datos,!kfold==i)   # Crea set Entren. para i iteracion
ModeloArbol   <-rpart(Desafiliado ~ .,data=Entrenamiento) # Crea Modelo
Prediccion    <- predict(ModeloArbol, Test,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
Aciertos      <-MC[1,1]/(MC[1,1]+MC[2,1])
Iteraciones   <-rbind(Iteraciones,
data.frame(iteracion=i, acierto=Aciertos))  # resultado en cada iteracion
}
Iteraciones   <-data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:Folds)
{
Test          <-subset(datos,kfold==i)    # Crea set TEST para i iteracion
Entrenamiento <-subset(datos,!kfold==i)   # Crea set Entren. para i iteracion
ModeloArbol   <-rpart(Desafiliado ~ .,data=Entrenamiento) # Crea Modelo
Prediccion    <- predict(ModeloArbol, train,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
Aciertos      <-MC[1,1]/(MC[1,1]+MC[2,1])
Iteraciones   <-rbind(Iteraciones,
data.frame(iteracion=i, acierto=Aciertos))  # resultado en cada iteracion
}
Iteraciones   <-data.frame(iteracion=NULL,aciertos=NULL)
for (i in 1:Folds)
{
Test          <-subset(datos,kfold==i)    # Crea set TEST para i iteracion
Entrenamiento <-subset(datos,!kfold==i)   # Crea set Entren. para i iteracion
ModeloArbol   <-rpart(modelo,data=train) # Crea Modelo
Prediccion    <- predict(ModeloArbol, train,type="class")  # Predice datos Test
MC            <-table(Test[, "Desafiliado"],Prediccion)   # Matriz de Confusión
Aciertos      <-MC[1,1]/(MC[1,1]+MC[2,1])
Iteraciones   <-rbind(Iteraciones,
data.frame(iteracion=i, acierto=Aciertos))  # resultado en cada iteracion
}
regfit.full = regsubsets(SSPL~Frequency*AOA*CL*FSV*SSDT, data = train, nvmax = 31, method = "exhaustive")
reg.summary = summary(regfit.full)
reg.summary
plot(reg.summary$rsq, xlab = " Número de variables ", ylab = "RSQ", type ="l", main = "Selección de variables")
#Modelo a ajustar
modelo = SSPL ~ Frequency + AOA + FSV + Frequency:AOA + Frequency:CL + AOA:CL + Frequency:FSV + AOA:FSV + CL:FSV + Frequency:SSDT + CL:SSDT + FSV:SSDT + Frequency:AOA:CL + Frequency:CL:FSV + Frequency:AOA:SSDT + Frequency:CL:SSDT + AOA:FSV:SSDT + Frequency:AOA:CL:FSV + Frequency:AOA:CL:SSDT + Frequency:CL:FSV:SSDT
#Ajuste de modelos
set.seed(1)
#Regresión generalizada múltiple
glmFit = glm(modelo, data = train)
pred = predict.glm(glmFit, test, type = "response", se.fit = TRUE)
names(pred)
#SVM
set.seed (1)
#Buscamos el valor çoptimo para cost y gamma
svm.fit = svm(modelo, data = train, kernel = "radial")
pred= predict(svm.fit, test)
plot(svm.fit, data=test)
################Eliminar todas las variables################################
library(caret)
install.packages("caret")
library(caret)
library(caret)
install.packages("caret")
set.seed(1)
indices = sample (dim(Airfoil)[1], 1200, replace=FALSE)
train = Airfoil[indices, ]
test = Airfoil[-indices, ]
SSPL.train = train[, "SSPL"]
SSPL.test = test[, "SSPL"]
regfit.full = regsubsets(SSPL~Frequency*AOA*CL*FSV*SSDT, data = train, nvmax = 31, method = "exhaustive")
reg.summary = summary(regfit.full)
reg.summary
plot(reg.summary$rsq, xlab = " Número de variables ", ylab = "RSQ", type ="l", main = "Selección de variables")
#Modelo a ajustar
modelo = SSPL ~ Frequency + AOA + FSV + Frequency:AOA + Frequency:CL + AOA:CL + Frequency:FSV + AOA:FSV + CL:FSV + Frequency:SSDT + CL:SSDT + FSV:SSDT + Frequency:AOA:CL + Frequency:CL:FSV + Frequency:AOA:SSDT + Frequency:CL:SSDT + AOA:FSV:SSDT + Frequency:AOA:CL:FSV + Frequency:AOA:CL:SSDT + Frequency:CL:FSV:SSDT
#Ajuste de modelos
set.seed(1)
#Regresión generalizada múltiple
lmFit = lm(modelo, data = train)
pred = predict.lm(lmFit, test, type = "response", se.fit = TRUE)
names(pred)
lmFit
summary(lmFit)
pred = predict.lm(lmFit, test, type = "response", se.fit = TRUE)
names(pred)
pred
?predict.lm
mean(pred$se.fit)
summary(pred)
?mse
??mse
library(Metrics)
install.packages("Metrics")
library(Metrics)
mse(SSPL.test,pred$fit)
mean(pred$se.fit)
mse(SSPL.test,pred$fit)
?predict
?mse
summary(lmFit)
104.24-97.41055
?annova
?anova
termplot(lmFit)
termplot(lmFit)
rocplot(lmFit)
0.65/0.75
0.75/0.65
