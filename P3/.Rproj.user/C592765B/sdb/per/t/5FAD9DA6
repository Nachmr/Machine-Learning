{
    "contents" : "path = \"~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P3\"\nsetwd(path)\nlibrary(ISLR)\nlibrary(e1071)\nlibrary(tree)\nlibrary(ROCR)\nlibrary(randomForest)\nlibrary(gbm)\n\n\n#################################################\n#Ejercicio 1\n#################################################\nfix(OJ)\nattach(OJ)\n\n#Apartado 1.1\n  set.seed(1)\n  indices = sample (dim(OJ)[1], 800, replace=FALSE)\n  train = OJ[indices, ]\n  test = OJ[-indices, ]\n  \n  set.seed(1)\n  svmfit = svm(Purchase ~ . , data = train, kernel =\"linear\" , cost =0.01 ,scale = FALSE )\n\n#Apartado 1.2\n  summary(svmfit)\n  \n  Purchase.train = train[, \"Purchase\"]\n  Purchase.test = test[, \"Purchase\"]\n    \n  #Error Train\n  set.seed(1)\n  svm.pred = predict (svmfit, train)\n  table(svm.pred, Purchase.train)\n  acierto.train = mean(svm.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n\n  #Error Test\n  set.seed(1)\n  svm.pred = predict (svmfit, test)\n  table(svm.pred, Purchase.test)\n  acierto.test = mean(svm.pred == Purchase.test) #Acierto\n  error.test = 1- acierto.test #Error\n  error.test\n\n#Apartado 1.3\n\n  rocplot = function ( pred , truth , ...) {\n      predob = prediction(pred, truth)\n      perf = performance(predob, \"tpr\", \"fpr\")\n      plot (perf ,...) \n      }\n  \n  #ROC para cost =0.001\n  set.seed(1)\n  svmfit.opt = svm(Purchase~. , data = train, kernel =\"linear\", cost =0.001, decision.values = T)\n  fitted = attributes(predict(svmfit.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #ROC para cost =0.01\n  set.seed(1)\n  svmfit.opt = svm(Purchase~. , data = train, kernel =\"linear\", cost =0.01, decision.values = T)\n  fitted = attributes(predict(svmfit.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #ROC para cost =0.1\n  set.seed(1)\n  svmfit.opt = svm(Purchase~. , data = train, kernel =\"linear\", cost =0.1, decision.values = T)\n  fitted = attributes(predict(svmfit.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #ROC para cost =1\n  set.seed(1)\n  svmfit.opt = svm(Purchase~. , data = train, kernel =\"linear\", cost =1, decision.values = T)\n  fitted = attributes(predict(svmfit.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #ROC para cost =10\n  set.seed(1)\n  svmfit.opt = svm(Purchase~. , data = train, kernel =\"linear\", cost =10, decision.values = T)\n  fitted = attributes(predict(svmfit.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Cost óptimo\n  set.seed(1)\n  tune.out = tune(svm, Purchase~. , data = train, kernel = \"linear\",ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10)))\n  tune.out\n\n#Apartado 1.4\n  set.seed(1)\n  svmfit = svm(Purchase~. , data = train, kernel =\"linear\", cost =0.01, decision.values = T)\n  \n  #Error Train\n  set.seed(1)\n  svm.pred = predict (svmfit, train)\n  table(svm.pred, Purchase.train)\n  acierto.train = mean(svm.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error Test\n  set.seed(1)\n  svm.pred = predict (svmfit, test)\n  table(svm.pred, Purchase.test)\n  acierto.test = mean(svm.pred == Purchase.test) #Acierto\n  error.test = 1- acierto.test #Error\n  error.test\n\n#Aparatado 1.5\n  #svm radial kernel\n  set.seed(1)\n  svmfit.rad = svm(Purchase~. , data = train, kernel =\"radial\", gamma =10, decision.values = T)\n  summary(svmfit.rad)\n  \n  #Error Train\n  set.seed(1)\n  svmrad.pred = predict (svmfit.rad, train)\n  table(svmrad.pred, Purchase.train)\n  acierto.train = mean(svmrad.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error Test\n  set.seed(1)\n  svmrad.pred = predict (svmfit.rad, test)\n  table(svmrad.pred, Purchase.test)\n  acierto.test = mean(svmrad.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n  \n  #Curva ROC para gamma = 10\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =10, decision.values = T)\n  fitted = attributes(predict(svmfit.rad.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para gamma = 1\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =1, decision.values = T)\n  fitted = attributes(predict(svmfit.rad.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para gamma = 0.1\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =0.1, decision.values = T)\n  fitted = attributes(predict(svmfit.rad.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para gamma = 0.01\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =0.01, decision.values = T)\n  fitted = attributes(predict(svmfit.rad.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para gamma = 0.001\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =0.001, decision.values = T)\n  fitted = attributes(predict(svmfit.rad.opt, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Calculamos el cost óptimo\n  set.seed(1)\n  tune.out = tune(svm, Purchase~. , data = train, kernel = \"radial\",ranges = list(gamma = c(10, 1, 0.1, 0.01, 0.001)))\n  tune.out\n  \n  #Calculamos los errores de train y test\n  set.seed(1)\n  svmfit.rad.opt = svm(Purchase~. , data = train, kernel =\"radial\", gamma =0.01, cost=1, decision.values = T)\n  \n  #Error Train\n  set.seed(1)\n  svmfit.rad.opt.pred = predict (svmfit, train)\n  table(svmfit.rad.opt.pred, Purchase.train)\n  acierto.train = mean(svmfit.rad.opt.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error Test\n  set.seed(1)\n  svmfit.rad.opt.pred = predict (svmfit, test)\n  table(svmfit.rad.opt.pred, Purchase.test)\n  acierto.test = mean(svmfit.rad.opt.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n\n#Apartado 1.6\n  #svm con nucleo polinómico\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 2, decision.values = T)\n  summary(svmfit.pol)\n  \n  #Error Train\n  set.seed(1)\n  svmpol.pred = predict (svmfit.pol, train)\n  table(svmpol.pred, Purchase.train)\n  acierto.train = mean(svmpol.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error Test\n  set.seed(1)\n  svmpol.pred = predict (svmfit.pol, test)\n  table(svmpol.pred, Purchase.test)\n  acierto.test = mean(svmpol.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n  \n  #Curva ROC para degree = 2\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 2, decision.values = T)\n  fitted = attributes(predict(svmfit.pol, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para degree = 3\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 3, decision.values = T)\n  fitted = attributes(predict(svmfit.pol, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para degree = 4\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 4, decision.values = T)\n  fitted = attributes(predict(svmfit.pol, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para degree = 5\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 5, decision.values = T)\n  fitted = attributes(predict(svmfit.pol, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Curva ROC para degree = 6\n  set.seed(1)\n  svmfit.pol = svm(Purchase~. , data = train, kernel =\"polynomial\", degree = 6, decision.values = T)\n  fitted = attributes(predict(svmfit.pol, train, decision.values = TRUE))$decision.values\n  rocplot(fitted, Purchase.train, main =\"Training Data\")\n  \n  #Calculamos el cost óptimo\n  set.seed(1)\n  tune.out = tune(svm, Purchase~. , data = train, kernel = \"polynomial\",ranges = list(degree = c(2,3,4,5,6)))\n  tune.out\n  \n  #Calculamos los errores de train y test\n  set.seed(1)\n  svmfit.pol.opt = svm(Purchase~. , data = train, kernel =\"radial\", degree = 3, decision.values = T)\n  \n  #Error Train\n  set.seed(1)\n  svmfit.pol.opt.pred = predict (svmfit.pol.opt, train)\n  table(svmfit.pol.opt.pred, Purchase.train)\n  acierto.train = mean(svmfit.pol.opt.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error Test\n  set.seed(1)\n  svmfit.pol.opt.pred = predict (svmfit.pol.opt, test)\n  table(svmfit.pol.opt.pred, Purchase.test)\n  acierto.test = mean(svmfit.pol.opt.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n\n\n\n\n\n#################################################\n# Ejercicio 2\n#################################################\n\n#Apartado 2.1\n\n  #usaré las mismas muestras que en el ejercico 1 para train y test\n  set.seed(1)\n  \n  tree.fit = tree(Purchase~., data = train)\n  tree.fit\n  \n  plot(tree.fit)\n\n#Apartado 2.2\n  summary(tree.fit)\n  tree.fit\n\n\n#Apartado 2.3\n  #Dibujo del arbol\n  plot(tree.fit)\n  tree.fit\n  \n  #Mejores 4\n  set.seed(1)\n  best4 = prune.misclass(tree.fit, best = 4)\n  best4\n\n#Apartado 2.4\n  set.seed(1)\n  tree.pred = predict(tree.fit, test, type =\"class\")\n  table(tree.pred, Purchase.test)\n  209/270\n  acierto.test = mean(tree.pred == Purchase.test) #Este es el acierto\n  acierto.test\n  error.test = 1 - acierto.test #Este el error\n  error.test\n\n#Apartado 2.5\n  set.seed(1)\n  cv.tree=cv.tree(tree.fit)\n  cv.tree\n\n#Apartado 2.6\n  plot(cv.tree$size, cv.tree$dev)\n\n#Apartado 2.7\n  set.seed(1)\n  prune.tree = prune.misclass(tree.fit , best = 4)\n  \n  #Error de train del árbol sin podar\n  set.seed(1)\n  tree.pred = predict(tree.fit, train, type =\"class\")\n  table(tree.pred, Purchase.train)\n  acierto.train = mean(tree.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error de test del arbol sin podar\n  set.seed(1)\n  tree.pred = predict(tree.fit, test, type =\"class\")\n  table(tree.pred, Purchase.test)\n  acierto.test = mean(tree.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n  \n  #Error de train del árbol podado\n  set.seed(1)\n  tree.pred = predict(prune.tree, train, type =\"class\")\n  table(tree.pred, Purchase.train)\n  acierto.train = mean(tree.pred == Purchase.train) #Este es el acierto\n  error.train = 1 - acierto.train #Este el error\n  error.train\n  \n  #Error de test del arbol podado\n  set.seed(1)\n  tree.pred = predict(prune.tree, test, type =\"class\")\n  table(tree.pred, Purchase.test)\n  acierto.test = mean(tree.pred == Purchase.test) #Este es el acierto\n  error.test = 1 - acierto.test #Este el error\n  error.test\n\n\n\n\n#################################################\n#Ejercicio 3\n#################################################\n\nfix(Hitters)\nattach(Hitters)\n\n#Apartado 3.1\n  Hitters=na.omit(Hitters)\n\n  Hitters[, \"Salary\"] = log(Hitters[, \"Salary\"])\n  \n  set.seed(1)\n  indices = sample (dim(Hitters)[1], 200, replace=FALSE)\n  train = Hitters[indices, ]\n  test = Hitters[-indices, ]\n\n#Apartado 3.2\n  set.seed(1)\n  \n  Salary.train = train[,\"Salary\"]\n  Salary.test = test[,\"Salary\"]\n  \n  MSE = rep(0, 7)\n  landa = c(0.001, 0.005, 0.01, 0.05, 0.5, 05, 1)\n\n  #train\n  set.seed(1)\n  indice = 1\n  for(i in landa){\n    boosting.fit = gbm(Salary~. , data = train, shrinkage = i , n.trees =1000, distribution = \"gaussian\", verbose = F, interaction.depth =4)\n    boosting.pred = predict(boosting.fit, newdata = train, n.trees = 1000)\n    MSE[indice] = mean((boosting.pred - Salary.train)^2)\n    indice = indice+1\n  }\n  \n  plot(landa, MSE, main = \"Train\")\n\n#Apartado 3.3\n  set.seed(1)\n  \n  #Boosting test\n  indice = 1\n  for(i in landa){\n    boosting.fit = gbm(Salary~. , data = test, shrinkage = i , n.trees =1000, distribution = \"gaussian\", verbose = F, interaction.depth =4)\n    boosting.pred = predict(boosting.fit, newdata = test, n.trees = 1000)\n    MSE[indice] = mean((boosting.pred - Salary.test)^2)\n    indice = indice+1\n  }\n  \n  plot(landa, MSE, main = \"Test\")\n  \n  #Regresión múltiple\n  set.seed(1)\n  reg.mul = lm(Salary~ . , data = test)\n  reg.mul.pred = predict(reg.mul, test)\n  MSE.reg.mul = mean((reg.mul.pred - Salary.test)^2)\n  MSE.reg.mul\n  \n  #Media de MSE de Boosting\n  mean.MSE = mean(MSE)\n  mean.MSE\n\n#Apartado 3.4\n\n  summary(boosting.fit)\n\n#Apartado 3.5\n  \n  set.seed(1)\n  bag.fit = randomForest(Salary~. , data = train)\n  bag.pred = predict(bag.fit, test)\n  MSE = mean((bag.pred - Salary.test)^2)\n  MSE\n\n",
    "created" : 1432223909955.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4230598830",
    "id" : "5FAD9DA6",
    "lastKnownWriteTime" : 1433106519,
    "path" : "~/Copy/Informatica/Carrera/3º/2º Cuatrimestre/AA/Prácticas/P3/P3.R",
    "project_path" : "P3.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}